# -*- coding: utf-8 -*-
"""
ç¥ç»ç®¡(ä¸‹é¢Œç¥ç»ç®¡)åˆ†å‰²æ¨ç†å™¨ - ONNXç‰ˆ
ç›´æ¥è¾“å‡ºç¬¦åˆã€Šå…¨æ™¯ç‰‡ JSON è§„èŒƒã€‹çš„ Standard Data

æƒé‡è·¯å¾„é€šè¿‡ config.yaml ç»Ÿä¸€é…ç½®ï¼Œä¸å†ä½¿ç”¨ç¡¬ç¼–ç è·¯å¾„ã€‚
"""
import os
import sys
import logging
import numpy as np
import onnxruntime as ort
import json
from typing import Optional, List

# åˆå§‹åŒ– logger
logger = logging.getLogger(__name__)

# --- ç¨³å¥è·¯å¾„è®¾ç½® ---
current_file_path = os.path.abspath(__file__)
current_dir = os.path.dirname(current_file_path)
project_root = os.path.abspath(os.path.join(current_dir, "../../../../"))
if project_root not in sys.path:
    sys.path.append(project_root)

# å¯¼å…¥ç»Ÿä¸€çš„æƒé‡è·å–å·¥å…·
from tools.weight_fetcher import ensure_weight_file, WeightFetchError
from tools.timer import timer

# å¼•ç”¨å‰å¤„ç† (è´Ÿè´£ç®—æ•°) - å‡è®¾æ‚¨ä¼šåˆ›å»ºä¸€ä¸ª neural_seg æ¨¡å—
try:
    from pipelines.pano.modules.neural_seg.pre_post import NeuralPrePostProcessor
    logger.info("Successfully imported NeuralPrePostProcessor from neural_seg.pre_post")
except ImportError as e:
    logger.error(f"Failed to import NeuralPrePostProcessor: {e}")
    try:
        from importlib.machinery import SourceFileLoader
        pre_post_path = os.path.join(os.path.dirname(__file__), 'pre_post.py')
        NeuralPrePostProcessor = SourceFileLoader('nerual_pre_post', pre_post_path).load_module().NeuralPrePostProcessor
        logger.info("Loaded NeuralPrePostProcessor via SourceFileLoader from neural_seg/pre_post.py")
    except Exception as e2:
        logger.error(f"Fallback load of NeuralPrePostProcessor failed: {e2}")
        class MockNeuralPrePostProcessor:
            def __init__(self, input_size): self.input_size = input_size
            def preprocess(self, img):
                return np.zeros((1, 3, *self.input_size), dtype=np.float32)
            def postprocess(self, out):
                return {"mask_shape": (self.input_size[0], self.input_size[1]), "raw_features": {"left": {"exists": False}, "right": {"exists": False}}, "analysis": {"is_symmetric": False}}
        NeuralPrePostProcessor = MockNeuralPrePostProcessor
        logger.warning("Using MockNeuralPrePostProcessor as fallback.")

# å¼•ç”¨æ ¼å¼åŒ–å·¥å…·
try:
    from pipelines.pano.utils import pano_report_utils
except ImportError:
    class MockReportUtils:
        @staticmethod
        def format_neural_report(masks_info):
            return {
                "NeuralCanalAssessment": {
                    "Left": {"Detected": bool(masks_info.get("left")), "Area": 0},
                    "Right": {"Detected": bool(masks_info.get("right")), "Area": 0}
                },
                "Conclusion": "ç¥ç»ç®¡åˆ†å‰²å®Œæˆã€‚"
            }


    pano_report_utils = MockReportUtils()
    logger.warning("Could not import real pano_report_utils. Using MockReportUtils.")


class NeuralPredictor:
    """
    ç¥ç»ç®¡(ä¸‹é¢Œç¥ç»ç®¡)åˆ†å‰²æ¨ç†å™¨ - ONNXç‰ˆ

    æƒé‡è·¯å¾„é€šè¿‡ config.yaml ç»Ÿä¸€é…ç½®ã€‚
    """

    def __init__(
            self,
            *,
            weights_key: Optional[str] = None,
            weights_force_download: bool = False,
            input_size: Optional[List[int]] = None,
    ):
        """
        åˆå§‹åŒ–ç¥ç»ç®¡åˆ†å‰²æ¨¡å—

        Args:
            weights_key: S3 æƒé‡è·¯å¾„ï¼ˆä» config.yaml ä¼ å…¥ï¼‰
            weights_force_download: æ˜¯å¦å¼ºåˆ¶é‡æ–°ä¸‹è½½æƒé‡
            input_size: è¾“å…¥å°ºå¯¸ [H, W]ï¼Œé»˜è®¤ [224, 224] (TransUNet æ ‡å‡†è¾“å…¥)
        """
        self.weights_key = weights_key
        self.weights_force_download = weights_force_download

        # å…¼å®¹ ONNX Runtime çš„æ‰§è¡Œå™¨
        # ä¼˜å…ˆä½¿ç”¨ CUDAï¼Œå¦‚æœæ²¡æœ‰åˆ™å›é€€åˆ° CPU
        self.providers = ['CUDAExecutionProvider', 'CPUExecutionProvider']

        # è¾“å…¥å°ºå¯¸
        if input_size:
            self.input_size = tuple(input_size)
        else:
            self.input_size = (224, 224)

        # NeuralPrePostProcessor è´Ÿè´£å›¾åƒé¢„å¤„ç†å’Œæ¨¡å‹è¾“å‡ºçš„åå¤„ç†
        # (ä¾‹å¦‚ï¼šMaskäºŒå€¼åŒ–ã€å·¦å³åˆ†å‰²ã€resizeå›åŸå›¾)
        self.pre_post = NeuralPrePostProcessor(input_size=self.input_size)

        self.session = None
        self.weights_path = None
        self._init_session()

    def _resolve_weights_path(self) -> str:
        """
        è§£ææƒé‡æ–‡ä»¶è·¯å¾„

        ä¼˜å…ˆçº§ï¼š
            1. é…ç½®çš„ weights_key
            2. ç¯å¢ƒå˜é‡ PANO_NEURAL_SEG_WEIGHTS
        """
        env_weights = os.getenv("PANO_NEURAL_SEG_WEIGHTS")

        candidates = [
            ("weights_key", self.weights_key),
            ("env", env_weights),
        ]

        for origin, candidate in candidates:
            if not candidate:
                continue

            if os.path.exists(candidate):
                logger.info(f"Using local weights file: {candidate} (from {origin})")
                return candidate

            if origin == "weights_key":
                try:
                    downloaded = ensure_weight_file(candidate, force_download=self.weights_force_download)
                    logger.info(f"Downloaded Neural Seg weights from S3 key '{candidate}' to {downloaded}")
                    return downloaded
                except WeightFetchError as e:
                    logger.warning(f"Failed to download from {origin}: {e}")
                    continue

        error_msg = (
            f"Neural canal segmentation model weights not found. "
            f"Please configure weights_key in config.yaml under pipelines.panoramic.modules.neural_seg"
        )
        raise FileNotFoundError(error_msg)

    def _init_session(self):
        """è§£ææƒé‡è·¯å¾„å¹¶åˆå§‹åŒ– ONNX Session"""
        logger.info("Initializing Neural Seg ONNX Runtime Session...")
        try:
            self.weights_path = self._resolve_weights_path()

            # åˆå§‹åŒ– ONNX Session
            self.session = ort.InferenceSession(self.weights_path, providers=self.providers)
            self.input_name = self.session.get_inputs()[0].name

            actual_providers = self.session.get_providers()
            logger.info(f"ONNX Session initialized. Providers: {actual_providers}")
            logger.info(f"Input name: {self.input_name}")

            # ç®€å•çš„ Warmup (å¯é€‰)
            # try:
            #     dummy = np.zeros((1, 3, *self.input_size), dtype=np.float32)
            #     self.session.run(None, {self.input_name: dummy})
            # except Exception:
            #     pass

        except Exception as e:
            logger.critical(f"Failed to initialize ONNX session: {e}")
            self.session = None
            raise

    def predict(self, image) -> dict:
        """
        æ‰§è¡Œæ¨ç†
        Returns:
            dict: { "left": mask_left, "right": mask_right, "full_mask": ... }
        """
        if self.session is None:
            logger.error("Model not initialized.")
            return {}

        logger.info(">>> [2/3] Running Neural Seg Inference...")

        try:
            # 1. å‰å¤„ç† (Pre-processing)
            # è¿™é‡Œè°ƒç”¨ NeuralPrePostProcessorï¼Œå®ƒåº”è¯¥è´Ÿè´£ï¼š
            # Resize(224) -> Normalize -> CHW -> Tensor/Numpy
            with timer.record("neural_seg.pre"):
                input_tensor = self.pre_post.preprocess(image)
                # ç¡®ä¿è½¬ä¸º numpy (å¦‚æœæ˜¯ tensor)
                if hasattr(input_tensor, 'cpu'):
                    input_numpy = input_tensor.cpu().numpy()
                else:
                    input_numpy = input_tensor

                logger.info(f"[predict] input shape: {input_numpy.shape}")

            # 2. ONNX æ¨ç† (Inference)
            with timer.record("neural_seg.inference"):
                # æ‰§è¡Œæ¨ç†
                onnx_outputs = self.session.run(None, {self.input_name: input_numpy})
                # TransUNet è¾“å‡ºé€šå¸¸æ˜¯ (1, num_classes, H, W)
                logger.info(f"[predict] ONNX output shape: {onnx_outputs[0].shape}")

            # 3. åå¤„ç† (Post-processing)
            # è¿™é‡Œè°ƒç”¨ NeuralPrePostProcessorï¼Œå®ƒåº”è¯¥è´Ÿè´£ï¼š
            # Argmax/Threshold -> Resizeå›åŸå›¾ -> åˆ‡åˆ†å·¦å³ä¾§ -> è¿‡æ»¤å™ªç‚¹
            with timer.record("neural_seg.post"):
                raw_results = self.pre_post.postprocess(onnx_outputs[0])

            return raw_results

        except Exception as e:
            logger.error(f"ONNX Prediction error: {e}")
            import traceback
            traceback.print_exc()
            return {}


# --- è‡ªåŠ¨åŒ–éªŒè¯è„šæœ¬ ---
if __name__ == "__main__":
    print("\n" + "=" * 50)
    print("   å¼€å§‹ NeuralPredictor (ONNX Segmentation) å…¨æµç¨‹éªŒè¯")
    print("=" * 50 + "\n")

    # 1. ç”Ÿæˆè™šæ‹Ÿå›¾ç‰‡
    print("ğŸ“¸ ç”Ÿæˆè™šæ‹Ÿæµ‹è¯•å›¾ç‰‡...")
    dummy_image = np.random.randint(0, 255, (1000, 2000, 3), dtype=np.uint8)

    # 2. åˆå§‹åŒ–é¢„æµ‹å™¨ (æ¨¡æ‹Ÿæœ¬åœ°æ–‡ä»¶å­˜åœ¨çš„æƒ…å†µ)
    # æ³¨æ„ï¼šè¿è¡Œå‰è¯·ç¡®ä¿ config.yaml é…ç½®æ­£ç¡®æˆ– weights_key æŒ‡å‘çœŸå®æ–‡ä»¶
    try:
        predictor = NeuralPredictor(
            weights_key="weights/panoramic/best_model_ramus_224.onnx"
        )

        # 3. æ‰§è¡Œé¢„æµ‹
        if predictor.session:
            result = predictor.predict(dummy_image)

            print("\n" + "-" * 20 + " éªŒè¯ç»“æœ " + "-" * 20)
            if result:
                print("âœ… æ¨ç†æˆåŠŸï¼")
                print(
                    f"Full Mask Shape: {result.get('full_mask', 'N/A').shape if result.get('full_mask') is not None else 'None'}")
                print(f"Left Detected: {result.get('left') is not None}")
                print(f"Right Detected: {result.get('right') is not None}")
            else:
                print("âŒ æ¨ç†è¿”å›ä¸ºç©ºã€‚")
    except Exception as e:
        print(f"âŒ åˆå§‹åŒ–å¤±è´¥ (å¯èƒ½æ˜¯ç¼ºå°‘æ¨¡å‹æ–‡ä»¶): {e}")

    print("\n" + "=" * 50)