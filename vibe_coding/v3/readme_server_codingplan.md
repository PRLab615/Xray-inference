# X-Ray æ¨ç†æœåŠ¡ç¼–ç è®¡åˆ’ v3 - Pipeline æ¶æ„æ¥å£è®¾è®¡

## æ–‡æ¡£è¯´æ˜

**ç‰ˆæœ¬**: v3.0  
**ç›®æ ‡**: ä» Mock æ•°æ®è¿‡æ¸¡åˆ°çœŸå® Pipeline æ¶æ„ï¼Œè®¾è®¡ç»Ÿä¸€çš„æ¨ç†ç®¡é“æ¥å£  
**åŸåˆ™**: æ¸è¿›å¼å°æ­¥è¿­ä»£ï¼Œæ¯æ­¥ç‹¬ç«‹å®Œæˆã€å¯éªŒè¯ã€å¯è¿è¡Œ  
**ä¾æ®**: `vibe_coding/v3/readme_server_lld.md`ï¼ˆè¯¦ç»†è®¾è®¡æ–‡æ¡£ï¼‰

---

## ä¸€ã€ç›®æ ‡æ¦‚è¿°

### v3 æ ¸å¿ƒå˜æ›´

ä» v2 çš„ Mock æ•°æ®åŠ è½½æ¨¡å¼ï¼Œå‡çº§ä¸ºçœŸå®çš„ Pipeline æ¶æ„ï¼š

1. **è®¾è®¡ BasePipeline åŸºç±»**ï¼šæä¾›ç»Ÿä¸€æ¥å£å’Œå…±äº«åŠŸèƒ½
2. **å®ç° PanoPipeline æ¥å£**ï¼šå…¨æ™¯ç‰‡æ¨ç†ç®¡é“ï¼ˆå†…éƒ¨å­æ¨¡å—ç”¨ TODO å ä½ï¼‰
3. **å®ç° CephPipeline æ¥å£**ï¼šä¾§ä½ç‰‡æ¨ç†ç®¡é“ï¼ˆéœ€è¦æ‚£è€…ä¿¡æ¯ï¼Œå†…éƒ¨å­æ¨¡å—ç”¨ TODO å ä½ï¼‰
4. **ä¿®æ”¹ tasks.py**ï¼šä»è°ƒç”¨ `load_mock_data()` æ”¹ä¸ºè°ƒç”¨ `Pipeline.run()`
5. **æ˜ç¡® report_utils æ¥å£**ï¼šå®šä¹‰è¾“å…¥è¾“å‡ºå¥‘çº¦ï¼Œä¸º v4 å®ç°åšå‡†å¤‡

### v3 vs v2 å…³é”®å·®å¼‚

| ç»´åº¦ | v2 å®ç° | v3 å®ç° |
|------|---------|---------|
| **æ•°æ®æ¥æº** | ä» example JSON æ–‡ä»¶åŠ è½½ | è°ƒç”¨çœŸå® Pipelineï¼ˆè™½ç„¶å†…éƒ¨æš‚æ—¶è¿”å›ç©ºç»“æ„ï¼‰ |
| **tasks.py** | è°ƒç”¨ `load_mock_data()` | è°ƒç”¨ `PanoPipeline.run()` / `CephPipeline.run()` |
| **Pipeline ç»“æ„** | ç©ºæ–‡ä»¶ï¼ˆTODO å ä½ï¼‰ | å®Œæ•´çš„ç±»æ¥å£å®šä¹‰ + å†…éƒ¨ TODO |
| **æ‚£è€…ä¿¡æ¯** | ä»…å­˜å‚¨ï¼Œæœªä½¿ç”¨ | ä¼ é€’ç»™ CephPipeline.run() |
| **å¯æ‰©å±•æ€§** | ä½ï¼ˆç¡¬ç¼–ç ï¼‰ | é«˜ï¼ˆç»Ÿä¸€æ¥å£ï¼Œæ˜“äºæ‰©å±•ï¼‰ |

---

## äºŒã€å—å½±å“çš„ç°æœ‰æ¨¡å—åˆ†æ

### 1. æ–°å¢æ¨¡å—

#### pipelines/base_pipeline.pyï¼ˆæ–°å¢ï¼‰
**ç›®çš„**: å®šä¹‰æ‰€æœ‰æ¨ç†ç®¡é“çš„åŸºç¡€æŠ½è±¡ç±»

**ä¾æ®**:
- éœ€è¦ä¸º PanoPipeline å’Œ CephPipeline æä¾›ç»Ÿä¸€çš„æ¥å£è§„èŒƒ
- å…±äº«çš„åŠŸèƒ½ï¼ˆæ—¥å¿—è®°å½•ã€å›¾åƒåŠ è½½ã€éªŒè¯ï¼‰éœ€è¦æŠ½è±¡åˆ°åŸºç±»
- ç¬¦åˆ DRY åŸåˆ™ï¼Œé¿å…é‡å¤ä»£ç 

**è®¾è®¡è¦ç‚¹**:
- æŠ½è±¡æ–¹æ³• `run(image_path, **kwargs)` å¼ºåˆ¶å­ç±»å®ç°
- å…±äº«æ–¹æ³• `_load_image()`, `_validate_image()`, `_log_step()`
- ä½¿ç”¨ ABC æ¨¡å—ç¡®ä¿æ¥å£å¥‘çº¦

### 2. é‡æ„æ¨¡å—

#### pipelines/pano/pano_pipeline.pyï¼ˆä»ç©ºæ–‡ä»¶é‡æ„ä¸ºå®Œæ•´æ¥å£ï¼‰
**ç›®çš„**: å…¨æ™¯ç‰‡æ¨ç†ç®¡é“ï¼Œåè°ƒå„ä¸ªå­æ¨¡å—å®Œæˆæ¨ç†

**ä¾æ®**:
- å…¨æ™¯ç‰‡æ¨ç†éœ€è¦åè°ƒå¤šä¸ªå­æ¨¡å—ï¼ˆteeth_seg, bone_density, joint_detection ç­‰ï¼‰
- éœ€è¦è°ƒç”¨ `pano_report_utils.generate_standard_output()` ç”Ÿæˆè§„èŒƒ JSON
- ä½œä¸º tasks.py çš„æ¨ç†å…¥å£ï¼Œå¿…é¡»æä¾›ç¨³å®šçš„æ¥å£

**è®¾è®¡è¦ç‚¹**:
- ç»§æ‰¿ BasePipeline
- å®ç° `run(image_path)` æ–¹æ³•
- å†…éƒ¨å­æ¨¡å—è°ƒç”¨ç”¨ TODO å ä½ï¼Œä½†ç»“æ„å®Œæ•´

#### pipelines/ceph/ceph_pipeline.pyï¼ˆä»ç©ºæ–‡ä»¶é‡æ„ä¸ºå®Œæ•´æ¥å£ï¼‰
**ç›®çš„**: ä¾§ä½ç‰‡æ¨ç†ç®¡é“ï¼Œéœ€è¦æ‚£è€…ä¿¡æ¯ä½œä¸ºå¿…éœ€è¾“å…¥

**ä¾æ®**:
- ä¾§ä½ç‰‡æ¨ç†éœ€è¦æ‚£è€…ä¿¡æ¯ï¼ˆgender, DentalAgeStageï¼‰ä½œä¸ºå¿…éœ€è¾“å…¥
- éœ€è¦è°ƒç”¨ `ceph_report_utils.generate_standard_output()` ç”Ÿæˆè§„èŒƒ JSON
- ä½œä¸º tasks.py çš„æ¨ç†å…¥å£ï¼Œå¿…é¡»æä¾›ç¨³å®šçš„æ¥å£

**è®¾è®¡è¦ç‚¹**:
- ç»§æ‰¿ BasePipeline
- å®ç° `run(image_path, patient_info)` æ–¹æ³•
- åŒ…å« `_validate_patient_info()` éªŒè¯æ–¹æ³•
- å†…éƒ¨å­æ¨¡å—è°ƒç”¨ç”¨ TODO å ä½ï¼Œä½†ç»“æ„å®Œæ•´

### 3. ä¿®æ”¹æ¨¡å—

#### server/tasks.pyï¼ˆä¸­åº¦ä¿®æ”¹ï¼‰
**ä¿®æ”¹èŒƒå›´**: 
- ç§»é™¤ `load_mock_data()` å‡½æ•°ï¼ˆçº¦ 50 è¡Œï¼‰
- ä¿®æ”¹ `analyze_task()` å‡½æ•°ä¸­çš„æ¨ç†è°ƒç”¨éƒ¨åˆ†ï¼ˆçº¦ 20 è¡Œï¼‰

**ä¾æ®**:
- éœ€è¦æ ¹æ® taskType å®ä¾‹åŒ–å¯¹åº”çš„ Pipeline
- è°ƒç”¨ `pipeline.run()` è·å–çœŸå®æ¨ç†ç»“æœï¼ˆè™½ç„¶ v3 è¿”å›ç©ºç»“æ„ï¼‰
- ä¿æŒå›è°ƒé€»è¾‘ä¸å˜ï¼ˆv2 å·²å®Œå–„ï¼‰

**å½±å“åˆ†æ**:
- âœ… å›è°ƒæµç¨‹æ— å½±å“
- âœ… ä»»åŠ¡å…ƒæ•°æ®ç»“æ„æ— å½±å“
- âœ… API å±‚æ— å½±å“

### 4. æ¥å£æ˜ç¡®æ¨¡å—

#### pipelines/pano/utils/pano_report_utils.pyï¼ˆæ¥å£æ˜ç¡®ï¼‰
**ç›®çš„**: æ˜ç¡®å‡½æ•°ç­¾åå’Œæ¥å£å¥‘çº¦

**ä¾æ®**:
- Pipeline éœ€è¦è°ƒç”¨ `generate_standard_output()` ç”Ÿæˆè§„èŒƒ JSON
- éœ€è¦æ˜ç¡®è¾“å…¥å‚æ•°ï¼ˆinference_resultsï¼‰å’Œè¾“å‡ºæ ¼å¼ï¼ˆdata å­—æ®µï¼‰

**è®¾è®¡è¦ç‚¹**:
- å®šä¹‰ `generate_standard_output(inference_results: dict) -> dict`
- æ·»åŠ è¯¦ç»†çš„æ–‡æ¡£å­—ç¬¦ä¸²ï¼ˆå‚æ•°è¯´æ˜ã€è¿”å›å€¼è¯´æ˜ï¼‰
- v3 å†…éƒ¨å®ç°è¿”å›ç©ºç»“æ„ï¼Œv4 å®ç°çœŸå®æ ¼å¼åŒ–é€»è¾‘

#### pipelines/ceph/utils/ceph_report_utils.pyï¼ˆæ¥å£æ˜ç¡®ï¼‰
**ç›®çš„**: æ˜ç¡®å‡½æ•°ç­¾åå’Œæ¥å£å¥‘çº¦

**ä¾æ®**:
- Pipeline éœ€è¦è°ƒç”¨ `generate_standard_output()` ç”Ÿæˆè§„èŒƒ JSON
- éœ€è¦æ˜ç¡®è¾“å…¥å‚æ•°ï¼ˆinference_results, patient_infoï¼‰å’Œè¾“å‡ºæ ¼å¼ï¼ˆdata å­—æ®µï¼‰

**è®¾è®¡è¦ç‚¹**:
- å®šä¹‰ `generate_standard_output(inference_results: dict, patient_info: dict) -> dict`
- æ·»åŠ è¯¦ç»†çš„æ–‡æ¡£å­—ç¬¦ä¸²ï¼ˆå‚æ•°è¯´æ˜ã€è¿”å›å€¼è¯´æ˜ï¼‰
- v3 å†…éƒ¨å®ç°è¿”å›ç©ºç»“æ„ï¼Œv4 å®ç°çœŸå®æ ¼å¼åŒ–é€»è¾‘

---

## ä¸‰ã€ä»£ç ç›®å½•ç»“æ„

### å˜æ›´å‰åå¯¹æ¯”

```
Xray-inference/
â”œâ”€â”€ pipelines/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base_pipeline.py                      # âœ… v3 æ–°å¢ï¼ˆçº¦ 150 è¡Œï¼‰
â”‚   â”‚
â”‚   â”œâ”€â”€ pano/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ pano_pipeline.py                  # âœ… v3 é‡æ„ï¼ˆv2: 0è¡Œ â†’ v3: 200è¡Œï¼‰
â”‚   â”‚   â”œâ”€â”€ modules/                          # â¸ï¸ v4 å®ç°
â”‚   â”‚   â”‚   â”œâ”€â”€ teeth_seg/
â”‚   â”‚   â”‚   â””â”€â”€ bone_density/
â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â””â”€â”€ pano_report_utils.py          # âœ… v3 æ¥å£æ˜ç¡®ï¼ˆv2: 16è¡Œ â†’ v3: 60è¡Œï¼‰
â”‚   â”‚
â”‚   â””â”€â”€ ceph/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ ceph_pipeline.py                  # âœ… v3 é‡æ„ï¼ˆv2: 0è¡Œ â†’ v3: 250è¡Œï¼‰
â”‚       â”œâ”€â”€ modules/                          # â¸ï¸ v4 å®ç°
â”‚       â””â”€â”€ utils/
â”‚           â”œâ”€â”€ __init__.py
â”‚           â””â”€â”€ ceph_report_utils.py          # âœ… v3 æ¥å£æ˜ç¡®ï¼ˆv2: 16è¡Œ â†’ v3: 60è¡Œï¼‰
â”‚
â””â”€â”€ server/
    â”œâ”€â”€ tasks.py                              # âœ… v3 ä¿®æ”¹ï¼ˆç§»é™¤ load_mock_dataï¼Œæ–°å¢ Pipeline è°ƒç”¨ï¼‰
    â”œâ”€â”€ api.py                                # ğŸ”’ v3 ä¸å˜
    â”œâ”€â”€ worker.py                             # ğŸ”’ v3 ä¸å˜
    â””â”€â”€ core/
        â”œâ”€â”€ persistence.py                    # ğŸ”’ v3 ä¸å˜
        â””â”€â”€ callback.py                       # ğŸ”’ v3 ä¸å˜
```

### ä»£ç è¡Œæ•°ä¼°ç®—

| æ–‡ä»¶ | v2 è¡Œæ•° | v3 è¡Œæ•° | å˜æ›´é‡ | å˜æ›´ç±»å‹ |
|------|---------|---------|--------|---------|
| `base_pipeline.py` | 0 | 150 | +150 | æ–°å¢è®¾è®¡ |
| `pano_pipeline.py` | 0 | 200 | +200 | æ–°å¢æ¥å£ |
| `ceph_pipeline.py` | 0 | 250 | +250 | æ–°å¢æ¥å£ |
| `pano_report_utils.py` | 16 | 60 | +44 | æ¥å£æ˜ç¡® |
| `ceph_report_utils.py` | 16 | 60 | +44 | æ¥å£æ˜ç¡® |
| `tasks.py` | 212 | 220 | +8 | ä¿®æ”¹æ¨ç†é€»è¾‘ |
| **æ€»è®¡** | **244** | **940** | **+696** | - |

**æ³¨**: è¡Œæ•°åŒ…å«æ³¨é‡Šã€æ–‡æ¡£å­—ç¬¦ä¸²ã€ç©ºè¡Œã€‚å®é™…é€»è¾‘ä»£ç çº¦å  50-60%ã€‚

---

## å››ã€æ¸è¿›å¼å°æ­¥è¿­ä»£å¼€å‘æ­¥éª¤

### æ­¥éª¤è®¾è®¡åŸåˆ™

1. **æ¯æ­¥ç‹¬ç«‹å®Œæ•´**ï¼šæ¯æ­¥å®Œæˆåï¼Œç¨‹åºèƒ½æˆåŠŸå¯åŠ¨å¹¶è¿è¡Œ
2. **å¯éªŒè¯æ€§**ï¼šæ¯æ­¥éƒ½æœ‰æ˜ç¡®çš„éªŒè¯æ–¹æ³•
3. **å¢é‡æ¼”è¿›**ï¼šæ¯æ­¥åœ¨å‰ä¸€æ­¥åŸºç¡€ä¸Šå¢åŠ æ–°åŠŸèƒ½
4. **æ¨¡å—åŒ–**ï¼šæ¯ä¸ªæ–‡ä»¶ä¸è¶…è¿‡ 500 è¡Œ

---

### æ­¥éª¤ 1ï¼šåˆ›å»º BasePipeline åŸºç±»

**ç›®æ ‡**: å»ºç«‹æ¨ç†ç®¡é“çš„ç»Ÿä¸€æ¥å£è§„èŒƒ

**å®ç°å†…å®¹**:
1. åˆ›å»º `pipelines/base_pipeline.py`
2. å®šä¹‰æŠ½è±¡åŸºç±» `BasePipeline`
3. å®ç°æŠ½è±¡æ–¹æ³• `run(image_path, **kwargs)`
4. å®ç°å…±äº«æ–¹æ³• `_load_image()`, `_validate_image()`, `_log_step()`

**æ¶‰åŠæ–‡ä»¶**:
- âœ… æ–°å¢: `pipelines/base_pipeline.py`

**ä»£ç è¦ç‚¹**:
```python
# pipelines/base_pipeline.py

from abc import ABC, abstractmethod
import logging
import os

class BasePipeline(ABC):
    """
    æ¨ç†ç®¡é“åŸºç±»
    
    æ‰€æœ‰å…·ä½“çš„ Pipelineï¼ˆPanoPipeline, CephPipelineï¼‰å¿…é¡»ç»§æ‰¿æ­¤ç±»å¹¶å®ç° run() æ–¹æ³•ã€‚
    """
    
    def __init__(self):
        """åˆå§‹åŒ– Pipeline"""
        self.logger = logging.getLogger(self.__class__.__name__)
        self.pipeline_type = "base"  # å­ç±»éœ€è¦†ç›–
        self.logger.info(f"{self.__class__.__name__} initialized")
    
    @abstractmethod
    def run(self, image_path: str, **kwargs) -> dict:
        """
        æ‰§è¡Œæ¨ç†æµç¨‹ï¼ˆæŠ½è±¡æ–¹æ³•ï¼Œå­ç±»å¿…é¡»å®ç°ï¼‰
        
        Args:
            image_path: å›¾åƒæ–‡ä»¶è·¯å¾„
            **kwargs: é¢å¤–å‚æ•°ï¼ˆå¦‚ patient_infoï¼‰
            
        Returns:
            dict: å®Œæ•´çš„ data å­—æ®µï¼Œç¬¦åˆã€Šæ¥å£å®šä¹‰.mdã€‹è§„èŒƒ
        """
        raise NotImplementedError("Subclass must implement run() method")
    
    def _load_image(self, image_path: str):
        """
        åŠ è½½å›¾åƒæ–‡ä»¶
        
        Args:
            image_path: å›¾åƒæ–‡ä»¶è·¯å¾„
            
        Returns:
            å›¾åƒå¯¹è±¡ï¼ˆv3 æš‚è¿”å› Noneï¼Œv4 å®ç°çœŸå®åŠ è½½ï¼‰
            
        Note:
            - v3: ä»…éªŒè¯æ–‡ä»¶å­˜åœ¨æ€§
            - v4: å®ç°çœŸå®çš„å›¾åƒåŠ è½½é€»è¾‘ï¼ˆJPG/PNG/DICOMï¼‰
        """
        if not os.path.exists(image_path):
            self.logger.error(f"Image file not found: {image_path}")
            raise FileNotFoundError(f"Image file not found: {image_path}")
        
        self.logger.info(f"Image file validated: {image_path}")
        # v3 å ä½ï¼šè¿”å› None
        return None
    
    def _validate_image(self, image) -> bool:
        """
        éªŒè¯å›¾åƒæ˜¯å¦æœ‰æ•ˆ
        
        Args:
            image: å›¾åƒå¯¹è±¡
            
        Returns:
            bool: å›¾åƒæ˜¯å¦æœ‰æ•ˆ
            
        Note:
            - v3: ç®€å•çš„ None æ£€æŸ¥
            - v4: å®ç°çœŸå®çš„éªŒè¯é€»è¾‘ï¼ˆå°ºå¯¸ã€æ ¼å¼ç­‰ï¼‰
        """
        # v3 å ä½ï¼šä»…æ£€æŸ¥æ˜¯å¦ä¸º Noneï¼ˆåœ¨ v3 ä¸­å§‹ç»ˆä¸º Noneï¼Œæ‰€ä»¥è·³è¿‡æ£€æŸ¥ï¼‰
        return True
    
    def _log_step(self, step_name: str, message: str = ""):
        """
        ç»Ÿä¸€çš„æ­¥éª¤æ—¥å¿—è®°å½•
        
        Args:
            step_name: æ­¥éª¤åç§°
            message: é™„åŠ ä¿¡æ¯
        """
        log_msg = f"[{self.pipeline_type}] {step_name}"
        if message:
            log_msg += f": {message}"
        self.logger.info(log_msg)
```

**éªŒè¯æ–¹æ³•**:
```bash
# åœ¨ Python äº¤äº’ç¯å¢ƒä¸­æµ‹è¯•
cd D:\ç¡•å£«æ–‡æ¡£\é¡¹ç›®\å£è…”\code\Xray-inference
python -c "from pipelines.base_pipeline import BasePipeline; print('BasePipeline loaded successfully')"
```

**é¢„æœŸç»“æœ**:
- âœ… æ–‡ä»¶åˆ›å»ºæˆåŠŸ
- âœ… å¯¼å…¥æ— é”™è¯¯
- âœ… æŠ½è±¡ç±»å®šä¹‰æ­£ç¡®

**å®Œæˆæ ‡å¿—**:
- [ ] `pipelines/base_pipeline.py` æ–‡ä»¶åˆ›å»º
- [ ] åŒ…å«å®Œæ•´çš„æ–‡æ¡£å­—ç¬¦ä¸²
- [ ] å¯¼å…¥æµ‹è¯•é€šè¿‡
- [ ] ç¨‹åºå¯æ­£å¸¸å¯åŠ¨ï¼ˆä¸å½±å“ç°æœ‰åŠŸèƒ½ï¼‰

---

### æ­¥éª¤ 2ï¼šå®ç° PanoPipeline æ¥å£

**ç›®æ ‡**: å®ç°å…¨æ™¯ç‰‡æ¨ç†ç®¡é“çš„å®Œæ•´æ¥å£ï¼ˆå†…éƒ¨å­æ¨¡å—ç”¨ TODO å ä½ï¼‰

**å®ç°å†…å®¹**:
1. é‡æ„ `pipelines/pano/pano_pipeline.py`
2. ç»§æ‰¿ `BasePipeline`ï¼Œå®ç° `run(image_path)` æ–¹æ³•
3. å®šä¹‰å†…éƒ¨æ–¹æ³• `_run_teeth_seg()`, `_run_bone_density()`, `_run_joint_detection()`, `_collect_results()`
4. è°ƒç”¨ `pano_report_utils.generate_standard_output()` ç”Ÿæˆè§„èŒƒ JSON

**æ¶‰åŠæ–‡ä»¶**:
- âœ… ä¿®æ”¹: `pipelines/pano/pano_pipeline.py`
- âœ… ä¿®æ”¹: `pipelines/pano/utils/pano_report_utils.py`

**ä»£ç è¦ç‚¹**:

```python
# pipelines/pano/pano_pipeline.py

from pipelines.base_pipeline import BasePipeline
from pipelines.pano.utils import pano_report_utils
import logging

logger = logging.getLogger(__name__)


class PanoPipeline(BasePipeline):
    """
    å…¨æ™¯ç‰‡æ¨ç†ç®¡é“
    
    è´Ÿè´£åè°ƒå„ä¸ªå­æ¨¡å—å®Œæˆå…¨æ™¯ç‰‡çš„å®Œæ•´åˆ†ææµç¨‹ï¼Œå¹¶ç”Ÿæˆç¬¦åˆè§„èŒƒçš„ JSON è¾“å‡ºã€‚
    """
    
    def __init__(self):
        """åˆå§‹åŒ–å…¨æ™¯ç‰‡ Pipeline"""
        super().__init__()
        self.pipeline_type = "panoramic"
        
        # TODO: v4 åˆå§‹åŒ–å­æ¨¡å—
        # self.teeth_seg_module = TeethSegModule()
        # self.bone_density_module = BoneDensityModule()
        
        logger.info("PanoPipeline initialized")
    
    def run(self, image_path: str) -> dict:
        """
        æ‰§è¡Œå…¨æ™¯ç‰‡æ¨ç†æµç¨‹
        
        Args:
            image_path: å›¾åƒæ–‡ä»¶è·¯å¾„
            
        Returns:
            dict: å®Œæ•´çš„ data å­—æ®µï¼Œç¬¦åˆã€Šè§„èŒƒï¼šå…¨æ™¯ç‰‡ JSONã€‹
            
        å·¥ä½œæµç¨‹:
            1. åŠ è½½å¹¶éªŒè¯å›¾åƒ
            2. ä¾æ¬¡è°ƒç”¨å„ä¸ªå­æ¨¡å—ï¼ˆv3: TODO å ä½ï¼‰
            3. æ”¶é›†æ‰€æœ‰æ¨ç†ç»“æœ
            4. è°ƒç”¨ report_utils ç”Ÿæˆè§„èŒƒ JSON
            5. è¿”å›å®Œæ•´çš„ data å­—æ®µ
        """
        self._log_step("å¼€å§‹å…¨æ™¯ç‰‡æ¨ç†", f"image_path={image_path}")
        
        # 1. åŠ è½½å›¾åƒ
        try:
            image = self._load_image(image_path)
        except Exception as e:
            logger.error(f"Failed to load image: {e}")
            raise
        
        # 2. éªŒè¯å›¾åƒ
        if not self._validate_image(image):
            raise ValueError(f"Invalid image: {image_path}")
        
        # 3. ä¾æ¬¡è°ƒç”¨å„ä¸ªå­æ¨¡å—ï¼ˆv3: TODO å ä½ï¼‰
        try:
            teeth_results = self._run_teeth_seg(image)
            bone_results = self._run_bone_density(image)
            joint_results = self._run_joint_detection(image)
            
        except Exception as e:
            logger.error(f"Inference failed: {e}")
            raise
        
        # 4. æ”¶é›†æ‰€æœ‰ç»“æœ
        inference_results = self._collect_results(
            teeth=teeth_results,
            bone=bone_results,
            joint=joint_results
        )
        
        # 5. ç”Ÿæˆç¬¦åˆè§„èŒƒçš„ JSON
        data_dict = pano_report_utils.generate_standard_output(inference_results)
        
        self._log_step("å…¨æ™¯ç‰‡æ¨ç†å®Œæˆ", f"data keys: {list(data_dict.keys())}")
        
        return data_dict
    
    def _run_teeth_seg(self, image) -> dict:
        """
        æ‰§è¡Œç‰™é½¿åˆ†å‰²
        
        Args:
            image: å›¾åƒå¯¹è±¡
            
        Returns:
            dict: ç‰™é½¿åˆ†å‰²ç»“æœ
            
        Note:
            - v3: è¿”å›ç©ºå­—å…¸ï¼ˆTODO å ä½ï¼‰
            - v4: å®ç°çœŸå®çš„ç‰™é½¿åˆ†å‰²é€»è¾‘
        """
        self._log_step("ç‰™é½¿åˆ†å‰²", "TODO")
        return {}
    
    def _run_bone_density(self, image) -> dict:
        """
        æ‰§è¡Œéª¨å¯†åº¦åˆ†æ
        
        Args:
            image: å›¾åƒå¯¹è±¡
            
        Returns:
            dict: éª¨å¯†åº¦åˆ†æç»“æœ
            
        Note:
            - v3: è¿”å›ç©ºå­—å…¸ï¼ˆTODO å ä½ï¼‰
            - v4: å®ç°çœŸå®çš„éª¨å¯†åº¦åˆ†æé€»è¾‘
        """
        self._log_step("éª¨å¯†åº¦åˆ†æ", "TODO")
        return {}
    
    def _run_joint_detection(self, image) -> dict:
        """
        æ‰§è¡Œå…³èŠ‚æ£€æµ‹
        
        Args:
            image: å›¾åƒå¯¹è±¡
            
        Returns:
            dict: å…³èŠ‚æ£€æµ‹ç»“æœ
            
        Note:
            - v3: è¿”å›ç©ºå­—å…¸ï¼ˆTODO å ä½ï¼‰
            - v4: å®ç°çœŸå®çš„å…³èŠ‚æ£€æµ‹é€»è¾‘
        """
        self._log_step("å…³èŠ‚æ£€æµ‹", "TODO")
        return {}
    
    def _collect_results(self, **module_results) -> dict:
        """
        æ”¶é›†æ‰€æœ‰å­æ¨¡å—çš„æ¨ç†ç»“æœ
        
        Args:
            **module_results: å„å­æ¨¡å—ç»“æœ
            
        Returns:
            dict: æ±‡æ€»çš„æ¨ç†ç»“æœ
        """
        self._log_step("æ”¶é›†ç»“æœ", f"{len(module_results)} modules")
        
        inference_results = {
            "teeth": module_results.get("teeth", {}),
            "bone": module_results.get("bone", {}),
            "joint": module_results.get("joint", {}),
        }
        
        return inference_results
```

```python
# pipelines/pano/utils/pano_report_utils.py

"""
å…¨æ™¯ç‰‡æŠ¥å‘Šç”Ÿæˆå·¥å…·
è´Ÿè´£ç”Ÿæˆç¬¦åˆè§„èŒƒçš„ JSON è¾“å‡º
"""

import logging
from typing import Dict, Any

logger = logging.getLogger(__name__)


def generate_standard_output(inference_results: Dict[str, Any]) -> Dict[str, Any]:
    """
    ç”Ÿæˆç¬¦åˆã€Šè§„èŒƒï¼šå…¨æ™¯ç‰‡ JSONã€‹çš„å®Œæ•´ data å­—æ®µ
    
    Args:
        inference_results: Pipeline æ”¶é›†çš„æ‰€æœ‰æ¨¡å—æ¨ç†ç»“æœ
            - teeth: ç‰™é½¿åˆ†å‰²ç»“æœ
            - bone: éª¨å¯†åº¦åˆ†æç»“æœ
            - joint: å…³èŠ‚æ£€æµ‹ç»“æœ
            
    Returns:
        dict: ç¬¦åˆã€Šè§„èŒƒï¼šå…¨æ™¯ç‰‡ JSONã€‹çš„å®Œæ•´ data å­—æ®µ
        
    ç¤ºä¾‹è¾“å‡º:
        {
            "Metadata": {...},
            "AnatomyResults": [...],
            "JointAndMandible": {...},
            "MaxillarySinus": [...],
            "PeriodontalCondition": {...},
            "MissingTeeth": [...],
            "ThirdMolarSummary": {...},
            "ToothAnalysis": [...]
        }
        
    Note:
        - v3: æ¥å£å®šä¹‰ï¼Œè¿”å›ç©ºç»“æ„
        - v4: å®Œæ•´å®ç°ï¼ˆæ ¼å¼åŒ–é€»è¾‘ï¼‰
    """
    logger.info("Generating standard output for panoramic analysis")
    
    # v3 å ä½ï¼šè¿”å›ç©ºç»“æ„ï¼ˆç¬¦åˆè§„èŒƒçš„å­—æ®µåï¼‰
    data_dict = {
        "Metadata": {},
        "AnatomyResults": [],
        "JointAndMandible": {},
        "MaxillarySinus": [],
        "PeriodontalCondition": {},
        "MissingTeeth": [],
        "ThirdMolarSummary": {},
        "ToothAnalysis": []
    }
    
    logger.warning("generate_standard_output not fully implemented (TODO)")
    return data_dict
```

**éªŒè¯æ–¹æ³•**:
```bash
# æµ‹è¯• PanoPipeline å®ä¾‹åŒ–å’Œè°ƒç”¨
cd D:\ç¡•å£«æ–‡æ¡£\é¡¹ç›®\å£è…”\code\Xray-inference
python -c "
from pipelines.pano.pano_pipeline import PanoPipeline
import os

# ä½¿ç”¨ä¸€ä¸ªå­˜åœ¨çš„æµ‹è¯•å›¾åƒï¼ˆæˆ–åˆ›å»ºä¸€ä¸ªç©ºæ–‡ä»¶ï¼‰
test_image = 'tmp/test_pano.jpg'
os.makedirs('tmp', exist_ok=True)
open(test_image, 'a').close()

pipeline = PanoPipeline()
result = pipeline.run(test_image)
print('PanoPipeline run success!')
print('Result keys:', list(result.keys()))
"
```

**é¢„æœŸç»“æœ**:
- âœ… PanoPipeline å®ä¾‹åŒ–æˆåŠŸ
- âœ… `run()` æ–¹æ³•æ‰§è¡ŒæˆåŠŸ
- âœ… è¿”å›åŒ…å« 8 ä¸ªé¡¶çº§å­—æ®µçš„å­—å…¸
- âœ… æ—¥å¿—è¾“å‡ºæ˜¾ç¤ºå„æ­¥éª¤æ‰§è¡Œ

**å®Œæˆæ ‡å¿—**:
- [ ] `pipelines/pano/pano_pipeline.py` é‡æ„å®Œæˆ
- [ ] `pipelines/pano/utils/pano_report_utils.py` æ¥å£æ˜ç¡®
- [ ] å•å…ƒæµ‹è¯•é€šè¿‡
- [ ] ç¨‹åºå¯æ­£å¸¸å¯åŠ¨ï¼ˆä¸å½±å“ç°æœ‰åŠŸèƒ½ï¼‰

---

### æ­¥éª¤ 3ï¼šå®ç° CephPipeline æ¥å£

**ç›®æ ‡**: å®ç°ä¾§ä½ç‰‡æ¨ç†ç®¡é“çš„å®Œæ•´æ¥å£ï¼ˆéœ€è¦æ‚£è€…ä¿¡æ¯ï¼Œå†…éƒ¨å­æ¨¡å—ç”¨ TODO å ä½ï¼‰

**å®ç°å†…å®¹**:
1. é‡æ„ `pipelines/ceph/ceph_pipeline.py`
2. ç»§æ‰¿ `BasePipeline`ï¼Œå®ç° `run(image_path, patient_info)` æ–¹æ³•
3. å®ç° `_validate_patient_info()` éªŒè¯æ‚£è€…ä¿¡æ¯
4. å®šä¹‰å†…éƒ¨æ–¹æ³• `_run_landmark_detection()`, `_run_measurements()`, `_collect_results()`
5. è°ƒç”¨ `ceph_report_utils.generate_standard_output()` ç”Ÿæˆè§„èŒƒ JSON

**æ¶‰åŠæ–‡ä»¶**:
- âœ… ä¿®æ”¹: `pipelines/ceph/ceph_pipeline.py`
- âœ… ä¿®æ”¹: `pipelines/ceph/utils/ceph_report_utils.py`

**ä»£ç è¦ç‚¹**:

```python
# pipelines/ceph/ceph_pipeline.py

from pipelines.base_pipeline import BasePipeline
from pipelines.ceph.utils import ceph_report_json
import logging

logger = logging.getLogger(__name__)


class CephPipeline(BasePipeline):
   """
   ä¾§ä½ç‰‡æ¨ç†ç®¡é“
   
   è´Ÿè´£åè°ƒå„ä¸ªå­æ¨¡å—å®Œæˆä¾§ä½ç‰‡çš„å®Œæ•´åˆ†ææµç¨‹ï¼Œå¹¶ç”Ÿæˆç¬¦åˆè§„èŒƒçš„ JSON è¾“å‡ºã€‚
   éœ€è¦æ‚£è€…ä¿¡æ¯ï¼ˆgender, DentalAgeStageï¼‰ä½œä¸ºå¿…éœ€è¾“å…¥ã€‚
   """

   def __init__(self):
      """åˆå§‹åŒ–ä¾§ä½ç‰‡ Pipeline"""
      super().__init__()
      self.pipeline_type = "cephalometric"

      # TODO: v4 åˆå§‹åŒ–å­æ¨¡å—
      # self.landmark_module = LandmarkDetectionModule()
      # self.measurement_module = MeasurementModule()

      logger.info("CephPipeline initialized")

   def run(self, image_path: str, patient_info: dict) -> dict:
      """
      æ‰§è¡Œä¾§ä½ç‰‡æ¨ç†æµç¨‹
      
      Args:
          image_path: å›¾åƒæ–‡ä»¶è·¯å¾„
          patient_info: æ‚£è€…ä¿¡æ¯ï¼ˆå¿…éœ€ï¼‰
              - gender: "Male" | "Female"
              - DentalAgeStage: "Permanent" | "Mixed"
          
      Returns:
          dict: å®Œæ•´çš„ data å­—æ®µï¼Œç¬¦åˆã€Šè§„èŒƒï¼šä¾§ä½ç‰‡ JSONã€‹
          
      å·¥ä½œæµç¨‹:
          1. éªŒè¯ patient_info
          2. åŠ è½½å¹¶éªŒè¯å›¾åƒ
          3. ä¾æ¬¡è°ƒç”¨å„ä¸ªå­æ¨¡å—ï¼ˆä¼ é€’ patient_infoï¼‰
          4. æ”¶é›†æ‰€æœ‰æ¨ç†ç»“æœ
          5. è°ƒç”¨ report_utils ç”Ÿæˆè§„èŒƒ JSONï¼ˆä¼ é€’ patient_infoï¼‰
          6. è¿”å›å®Œæ•´çš„ data å­—æ®µ
      """
      # 0. éªŒè¯ patient_info
      self._validate_patient_info(patient_info)

      self._log_step("å¼€å§‹ä¾§ä½ç‰‡æ¨ç†", f"image_path={image_path}, patient_info={patient_info}")

      # 1. åŠ è½½å›¾åƒ
      try:
         image = self._load_image(image_path)
      except Exception as e:
         logger.error(f"Failed to load image: {e}")
         raise

      # 2. éªŒè¯å›¾åƒ
      if not self._validate_image(image):
         raise ValueError(f"Invalid image: {image_path}")

      # 3. ä¾æ¬¡è°ƒç”¨å„ä¸ªå­æ¨¡å—ï¼ˆä¼ é€’ patient_infoï¼‰
      try:
         landmark_results = self._run_landmark_detection(image, patient_info)
         measurement_results = self._run_measurements(landmark_results, patient_info)

      except Exception as e:
         logger.error(f"Inference failed: {e}")
         raise

      # 4. æ”¶é›†æ‰€æœ‰ç»“æœ
      inference_results = self._collect_results(
         landmarks=landmark_results,
         measurements=measurement_results
      )

      # 5. ç”Ÿæˆç¬¦åˆè§„èŒƒçš„ JSONï¼ˆä¼ é€’ patient_infoï¼‰
      data_dict = ceph_report_json.generate_standard_output(inference_results, patient_info)

      self._log_step("ä¾§ä½ç‰‡æ¨ç†å®Œæˆ", f"data keys: {list(data_dict.keys())}")

      return data_dict

   def _validate_patient_info(self, patient_info: dict):
      """
      éªŒè¯æ‚£è€…ä¿¡æ¯çš„æœ‰æ•ˆæ€§
      
      Args:
          patient_info: æ‚£è€…ä¿¡æ¯å­—å…¸
          
      Raises:
          ValueError: patient_info æ— æ•ˆ
          
      Note:
          - gender å¿…é¡»ä¸º "Male" æˆ– "Female"
          - DentalAgeStage å¿…é¡»ä¸º "Permanent" æˆ– "Mixed"
      """
      if not patient_info:
         raise ValueError("patient_info is required for cephalometric analysis")

      gender = patient_info.get("gender")
      dental_age_stage = patient_info.get("DentalAgeStage")

      if gender not in ["Male", "Female"]:
         raise ValueError(f"Invalid gender: {gender}, must be 'Male' or 'Female'")

      if dental_age_stage not in ["Permanent", "Mixed"]:
         raise ValueError(f"Invalid DentalAgeStage: {dental_age_stage}, must be 'Permanent' or 'Mixed'")

      logger.info(f"patient_info validated: gender={gender}, DentalAgeStage={dental_age_stage}")

   def _run_landmark_detection(self, image, patient_info: dict) -> dict:
      """
      æ‰§è¡Œå…³é”®ç‚¹æ£€æµ‹
      
      Args:
          image: å›¾åƒå¯¹è±¡
          patient_info: æ‚£è€…ä¿¡æ¯
          
      Returns:
          dict: å…³é”®ç‚¹æ£€æµ‹ç»“æœ
          
      Note:
          - v3: è¿”å›ç©ºå­—å…¸ï¼ˆTODO å ä½ï¼‰
          - v4: å®ç°çœŸå®çš„å…³é”®ç‚¹æ£€æµ‹é€»è¾‘
      """
      self._log_step("å…³é”®ç‚¹æ£€æµ‹", f"patient_info={patient_info}, TODO")
      return {}

   def _run_measurements(self, landmark_results: dict, patient_info: dict) -> dict:
      """
      åŸºäºå…³é”®ç‚¹è®¡ç®—æµ‹é‡å€¼
      
      Args:
          landmark_results: å…³é”®ç‚¹æ£€æµ‹ç»“æœ
          patient_info: æ‚£è€…ä¿¡æ¯
          
      Returns:
          dict: æµ‹é‡ç»“æœ
          
      Note:
          - v3: è¿”å›ç©ºå­—å…¸ï¼ˆTODO å ä½ï¼‰
          - v4: å®ç°çœŸå®çš„æµ‹é‡é€»è¾‘
      """
      self._log_step("å¤´å½±æµ‹é‡", f"patient_info={patient_info}, TODO")
      return {}

   def _collect_results(self, **module_results) -> dict:
      """
      æ”¶é›†æ‰€æœ‰å­æ¨¡å—çš„æ¨ç†ç»“æœ
      
      Args:
          **module_results: å„å­æ¨¡å—ç»“æœ
          
      Returns:
          dict: æ±‡æ€»çš„æ¨ç†ç»“æœ
      """
      self._log_step("æ”¶é›†ç»“æœ", f"{len(module_results)} modules")

      inference_results = {
         "landmarks": module_results.get("landmarks", {}),
         "measurements": module_results.get("measurements", {}),
      }

      return inference_results
```

```python
# pipelines/ceph/utils/ceph_report_json.py

"""
ä¾§ä½ç‰‡æŠ¥å‘Šç”Ÿæˆå·¥å…·
è´Ÿè´£ç”Ÿæˆç¬¦åˆè§„èŒƒçš„ JSON è¾“å‡º
"""

import logging
from typing import Dict, Any

logger = logging.getLogger(__name__)


def generate_standard_output(
    inference_results: Dict[str, Any],
    patient_info: Dict[str, str]
) -> Dict[str, Any]:
    """
    ç”Ÿæˆç¬¦åˆã€Šè§„èŒƒï¼šä¾§ä½ç‰‡ JSONã€‹çš„å®Œæ•´ data å­—æ®µ
    
    Args:
        inference_results: Pipeline æ”¶é›†çš„æ‰€æœ‰æ¨¡å—æ¨ç†ç»“æœ
            - landmarks: å…³é”®ç‚¹æ£€æµ‹ç»“æœ
            - measurements: å¤´å½±æµ‹é‡ç»“æœ
        patient_info: æ‚£è€…ä¿¡æ¯
            - gender: "Male" | "Female"
            - DentalAgeStage: "Permanent" | "Mixed"
            
    Returns:
        dict: ç¬¦åˆã€Šè§„èŒƒï¼šä¾§ä½ç‰‡ JSONã€‹çš„å®Œæ•´ data å­—æ®µ
        
    ç¤ºä¾‹è¾“å‡º:
        {
            "ImageSpacing": {...},
            "VisibilityMetrics": {...},
            "CephalometricMeasurements": {...},
            "KeyPoints": [...],
            "Measurements": [...]
        }
        
    Note:
        - v3: æ¥å£å®šä¹‰ï¼Œè¿”å›ç©ºç»“æ„
        - v4: å®Œæ•´å®ç°ï¼ˆæ ¼å¼åŒ–é€»è¾‘ï¼‰
        - patient_info å¯èƒ½å½±å“æµ‹é‡å€¼çš„è§£é‡Šå’Œæ­£å¸¸èŒƒå›´åˆ¤æ–­
    """
    logger.info(f"Generating standard output for cephalometric analysis: patient_info={patient_info}")
    
    # v3 å ä½ï¼šè¿”å›ç©ºç»“æ„ï¼ˆç¬¦åˆè§„èŒƒçš„å­—æ®µåï¼‰
    data_dict = {
        "ImageSpacing": {},
        "VisibilityMetrics": {},
        "CephalometricMeasurements": {},
        "KeyPoints": [],
        "Measurements": []
    }
    
    logger.warning("generate_standard_output not fully implemented (TODO)")
    return data_dict
```

**éªŒè¯æ–¹æ³•**:
```bash
# æµ‹è¯• CephPipeline å®ä¾‹åŒ–å’Œè°ƒç”¨
cd D:\ç¡•å£«æ–‡æ¡£\é¡¹ç›®\å£è…”\code\Xray-inference
python -c "
from pipelines.ceph.ceph_pipeline import CephPipeline
import os

# ä½¿ç”¨ä¸€ä¸ªå­˜åœ¨çš„æµ‹è¯•å›¾åƒ
test_image = 'tmp/test_ceph.jpg'
os.makedirs('tmp', exist_ok=True)
open(test_image, 'a').close()

# æµ‹è¯•æ‚£è€…ä¿¡æ¯
patient_info = {
    'gender': 'Male',
    'DentalAgeStage': 'Permanent'
}

pipeline = CephPipeline()
result = pipeline.run(test_image, patient_info)
print('CephPipeline run success!')
print('Result keys:', list(result.keys()))
"
```

**é¢„æœŸç»“æœ**:
- âœ… CephPipeline å®ä¾‹åŒ–æˆåŠŸ
- âœ… `run()` æ–¹æ³•æ‰§è¡ŒæˆåŠŸ
- âœ… patient_info éªŒè¯é€šè¿‡
- âœ… è¿”å›åŒ…å« 5 ä¸ªé¡¶çº§å­—æ®µçš„å­—å…¸
- âœ… æ—¥å¿—è¾“å‡ºæ˜¾ç¤ºå„æ­¥éª¤æ‰§è¡Œ

**å®Œæˆæ ‡å¿—**:
- [ ] `pipelines/ceph/ceph_pipeline.py` é‡æ„å®Œæˆ
- [ ] `pipelines/ceph/utils/ceph_report_utils.py` æ¥å£æ˜ç¡®
- [ ] patient_info éªŒè¯é€»è¾‘æ­£ç¡®
- [ ] å•å…ƒæµ‹è¯•é€šè¿‡
- [ ] ç¨‹åºå¯æ­£å¸¸å¯åŠ¨ï¼ˆä¸å½±å“ç°æœ‰åŠŸèƒ½ï¼‰

---

### æ­¥éª¤ 4ï¼šä¿®æ”¹ tasks.py è°ƒç”¨ Pipeline

**ç›®æ ‡**: å°† tasks.py ä»è°ƒç”¨ `load_mock_data()` æ”¹ä¸ºè°ƒç”¨çœŸå®çš„ Pipeline

**å®ç°å†…å®¹**:
1. ç§»é™¤ `load_mock_data()` å‡½æ•°
2. ä¿®æ”¹ `analyze_task()` å‡½æ•°ï¼š
   - å¯¼å…¥ PanoPipeline å’Œ CephPipeline
   - æ ¹æ® taskType å®ä¾‹åŒ–å¯¹åº”çš„ Pipeline
   - è°ƒç”¨ `pipeline.run()` è·å–æ¨ç†ç»“æœ
   - ä¿æŒå›è°ƒé€»è¾‘ä¸å˜

**æ¶‰åŠæ–‡ä»¶**:
- âœ… ä¿®æ”¹: `server/tasks.py`

**ä»£ç è¦ç‚¹**:

```python
# server/tasks.pyï¼ˆä¿®æ”¹éƒ¨åˆ†ï¼‰

# v3 æ–°å¢ï¼šå¯¼å…¥ Pipeline
from pipelines.pano.pano_pipeline import PanoPipeline
from pipelines.ceph.ceph_pipeline import CephPipeline

# âŒ ç§»é™¤ load_mock_data() å‡½æ•°ï¼ˆç¬¬ 24-67 è¡Œï¼‰

@celery_app.task(name='server.tasks.analyze_task', bind=True)
def analyze_task(self, task_id: str):
    """
    å¼‚æ­¥æ¨ç†ä»»åŠ¡ï¼ˆv3 åè®®ï¼šçœŸå® Pipelineï¼‰
    
    å·¥ä½œæµç¨‹:
        1. ä» Redis è·å–ä»»åŠ¡å…ƒæ•°æ®ï¼ˆv2 æ‰©å±•å­—æ®µï¼‰
        2. æ£€æŸ¥å›¾åƒæ–‡ä»¶æ˜¯å¦å­˜åœ¨
        3. æ ¹æ® taskType å®ä¾‹åŒ–å¯¹åº”çš„ Pipelineï¼ˆv3 æ–°å¢ï¼‰
        4. è°ƒç”¨ pipeline.run() è·å–çœŸå®æ¨ç†ç»“æœï¼ˆv3 æ–°å¢ï¼‰
        5. æ„é€ å›è°ƒè´Ÿè½½ v3ï¼ˆdata æ¥è‡ª Pipelineï¼‰
        6. å‘é€ HTTP å›è°ƒ
        7. æ¸…ç† Redis å…ƒæ•°æ®ï¼ˆå›è°ƒæˆåŠŸæ—¶ï¼‰
        
    å˜æ›´ç‚¹ï¼ˆv2 â†’ v3ï¼‰:
        - âŒ ç§»é™¤ load_mock_data() è°ƒç”¨
        - âœ… æ–°å¢ Pipeline å®ä¾‹åŒ–å’Œè°ƒç”¨
        - âœ… ä¼ é€’ patient_info ç»™ CephPipeline
    """
    logger.info(f"Task started: {task_id}")
    
    # ... å‰é¢çš„ä»£ç ä¿æŒä¸å˜ ...
    
    # 2. æ£€æŸ¥å›¾åƒæ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(image_path):
        logger.error(f"Image file not found: {image_path}")
        return
    
    # 3. æ ¹æ® taskType å®ä¾‹åŒ– Pipeline å¹¶æ‰§è¡Œæ¨ç†ï¼ˆv3 æ–°å¢ï¼‰
    try:
        if task_type == 'panoramic':
            # å…¨æ™¯ç‰‡æ¨ç†
            logger.info(f"Instantiating PanoPipeline for {task_id}")
            pipeline = PanoPipeline()
            data_dict = pipeline.run(image_path=image_path)
            
        elif task_type == 'cephalometric':
            # ä¾§ä½ç‰‡æ¨ç†ï¼ˆéœ€è¦ patient_infoï¼‰
            logger.info(f"Instantiating CephPipeline for {task_id}")
            pipeline = CephPipeline()
            data_dict = pipeline.run(image_path=image_path, patient_info=patient_info)
            
        else:
            logger.error(f"Unknown task_type: {task_type}")
            return
        
        logger.info(f"Pipeline execution completed for {task_id}")
    
    except Exception as e:
        # v3 æš‚ä¸å®ç°é”™è¯¯å›è°ƒï¼ˆå»¶ååˆ° v4ï¼‰
        logger.error(f"Pipeline execution failed: {task_id}, {e}", exc_info=True)
        return
    
    # 4. æ„é€  CallbackPayload v3ï¼ˆdata æ¥è‡ª Pipelineï¼‰
    payload_v3 = {
        "taskId": task_id,
        "status": "SUCCESS",
        "timestamp": datetime.now(timezone.utc).isoformat(),
        "metadata": client_metadata,
        "requestParameters": {
            "taskType": task_type,
            "imageUrl": image_url
        },
        "data": data_dict,  # v3: æ¥è‡ª Pipeline çœŸå®æ¨ç†
        "error": None
    }
    
    # 5. å‘é€å›è°ƒ v3
    success = callback_mgr.send_callback(callback_url, payload_v3)
    
    # 6. æ¸…ç†ä»»åŠ¡å…ƒæ•°æ®ï¼ˆä»…å½“å›è°ƒæˆåŠŸæ—¶ï¼‰
    if success:
        persistence.delete_task(task_id)
        logger.info(f"Task completed and cleaned: {task_id}")
    else:
        logger.warning(f"Task completed but callback failed, metadata retained: {task_id}")
```

**å…³é”®å˜æ›´æ€»ç»“**:

| ä»£ç å— | v2 å®ç° | v3 å®ç° |
|--------|---------|---------|
| **import** | æ—  Pipeline å¯¼å…¥ | âœ… `from pipelines.pano.pano_pipeline import PanoPipeline`<br/>âœ… `from pipelines.ceph.ceph_pipeline import CephPipeline` |
| **æ¨ç†è°ƒç”¨** | `data_dict = load_mock_data(task_type)` | âœ… `pipeline = PanoPipeline()` / `CephPipeline()`<br/>âœ… `data_dict = pipeline.run(...)` |
| **å‚æ•°ä¼ é€’** | æ— å‚æ•° | âœ… å…¨æ™¯ç‰‡ï¼š`run(image_path)`<br/>âœ… ä¾§ä½ç‰‡ï¼š`run(image_path, patient_info)` |
| **æ•°æ®æ¥æº** | é™æ€ JSON æ–‡ä»¶ | âœ… Pipeline çœŸå®æ¨ç†ç»“æœï¼ˆv3 è¿”å›ç©ºç»“æ„ï¼‰ |

**éªŒè¯æ–¹æ³•**:
```bash
# 1. å¯åŠ¨ Redis
# 2. å¯åŠ¨ Worker
cd D:\ç¡•å£«æ–‡æ¡£\é¡¹ç›®\å£è…”\code\Xray-inference
python main_worker.py

# 3. å¯åŠ¨ API æœåŠ¡ï¼ˆå¦ä¸€ä¸ªç»ˆç«¯ï¼‰
python main_api.py

# 4. å‘é€æµ‹è¯•è¯·æ±‚ï¼ˆå¦ä¸€ä¸ªç»ˆç«¯ï¼‰
python send_request_test.py
```

**é¢„æœŸç»“æœ**:
- âœ… API æœåŠ¡æ­£å¸¸å¯åŠ¨
- âœ… Worker æ­£å¸¸å¯åŠ¨
- âœ… å‘é€å…¨æ™¯ç‰‡è¯·æ±‚ï¼ŒPipeline æ‰§è¡ŒæˆåŠŸ
- âœ… å‘é€ä¾§ä½ç‰‡è¯·æ±‚ï¼ˆå¸¦ patient_infoï¼‰ï¼ŒPipeline æ‰§è¡ŒæˆåŠŸ
- âœ… å›è°ƒ payload åŒ…å«ç©ºç»“æ„çš„ data å­—æ®µ
- âœ… æ—¥å¿—æ˜¾ç¤º Pipeline å„æ­¥éª¤æ‰§è¡Œ

**å®Œæˆæ ‡å¿—**:
- [ ] `server/tasks.py` ä¿®æ”¹å®Œæˆ
- [ ] `load_mock_data()` å‡½æ•°å·²ç§»é™¤
- [ ] Pipeline è°ƒç”¨é€»è¾‘æ­£ç¡®
- [ ] ç«¯åˆ°ç«¯æµ‹è¯•é€šè¿‡
- [ ] å›è°ƒæ•°æ®æ ¼å¼æ­£ç¡®ï¼ˆè™½ç„¶æ˜¯ç©ºç»“æ„ï¼‰

---

## äº”ã€å®ç°æµç¨‹å›¾

### æ•´ä½“æ¶æ„æµç¨‹ï¼ˆv3ï¼‰

```mermaid
flowchart TD
    A[å®¢æˆ·ç«¯] -->|POST /api/v1/analyze| B[server/api.py]
    B -->|save_task| C[Redis]
    B -->|analyze_task.delay| D[Celery Queue]
    
    D -->|Worker æ‹‰å–| E[main_worker.py]
    E -->|æ‰§è¡Œ| F[server/tasks.py::analyze_task]
    
    F -->|get_task| C
    F -->|æå– taskType, imagePath| G{taskType?}
    
    G -->|panoramic| H[PanoPipeline]
    G -->|cephalometric| I[CephPipeline]
    
    H -->|run image_path| J[BasePipeline::run]
    I -->|run image_path, patient_info| K[BasePipeline::run]
    
    J -->|1. _load_image| L[éªŒè¯æ–‡ä»¶å­˜åœ¨]
    J -->|2. _run_teeth_seg| M[TODO v4]
    J -->|3. _run_bone_density| N[TODO v4]
    J -->|4. _collect_results| O[æ±‡æ€»ç»“æœ]
    J -->|5. generate_standard_output| P[pano_report_utils]
    
    K -->|1. _validate_patient_info| Q[éªŒè¯æ‚£è€…ä¿¡æ¯]
    K -->|2. _load_image| R[éªŒè¯æ–‡ä»¶å­˜åœ¨]
    K -->|3. _run_landmark_detection| S[TODO v4]
    K -->|4. _run_measurements| T[TODO v4]
    K -->|5. _collect_results| U[æ±‡æ€»ç»“æœ]
    K -->|6. generate_standard_output| V[ceph_report_utils]
    
    P -->|è¿”å›ç©ºç»“æ„| W[data_dict]
    V -->|è¿”å›ç©ºç»“æ„| W
    
    W -->|æ„é€  payload_v3| X[CallbackPayload]
    X -->|send_callback| Y[å®¢æˆ·ç«¯å›è°ƒ URL]
    
    Y -->|æˆåŠŸ| Z[delete_task]
    Z --> C
```

### æ­¥éª¤æ‰§è¡Œæµç¨‹

```mermaid
flowchart LR
    A[æ­¥éª¤ 1<br/>åˆ›å»º BasePipeline] --> B[æ­¥éª¤ 2<br/>å®ç° PanoPipeline]
    B --> C[æ­¥éª¤ 3<br/>å®ç° CephPipeline]
    C --> D[æ­¥éª¤ 4<br/>ä¿®æ”¹ tasks.py]
    
    A -.éªŒè¯.-> A1[å¯¼å…¥æµ‹è¯•]
    B -.éªŒè¯.-> B1[å•å…ƒæµ‹è¯• PanoPipeline]
    C -.éªŒè¯.-> C1[å•å…ƒæµ‹è¯• CephPipeline]
    D -.éªŒè¯.-> D1[ç«¯åˆ°ç«¯æµ‹è¯•]
    
    style A fill:#e1f5ff
    style B fill:#fff4e1
    style C fill:#ffe1f5
    style D fill:#e1ffe1
```

### ç±»ç»§æ‰¿å…³ç³»

```mermaid
classDiagram
    class BasePipeline {
        <<abstract>>
        +str pipeline_type
        +Logger logger
        +__init__()
        +run(image_path, kwargs)* dict
        #_load_image(image_path) object
        #_validate_image(image) bool
        #_log_step(step_name, message)
    }
    
    class PanoPipeline {
        +str pipeline_type = "panoramic"
        +__init__()
        +run(image_path) dict
        -_run_teeth_seg(image) dict
        -_run_bone_density(image) dict
        -_run_joint_detection(image) dict
        -_collect_results(**results) dict
    }
    
    class CephPipeline {
        +str pipeline_type = "cephalometric"
        +__init__()
        +run(image_path, patient_info) dict
        -_validate_patient_info(patient_info)
        -_run_landmark_detection(image, patient_info) dict
        -_run_measurements(landmarks, patient_info) dict
        -_collect_results(**results) dict
    }
    
    class PanoReportUtils {
        <<module>>
        +generate_standard_output(inference_results) dict
    }
    
    class CephReportUtils {
        <<module>>
        +generate_standard_output(inference_results, patient_info) dict
    }
    
    BasePipeline <|-- PanoPipeline : ç»§æ‰¿
    BasePipeline <|-- CephPipeline : ç»§æ‰¿
    PanoPipeline ..> PanoReportUtils : è°ƒç”¨
    CephPipeline ..> CephReportUtils : è°ƒç”¨
```

### æ—¶åºå›¾ï¼ˆv3 Pipeline è°ƒç”¨ï¼‰

```mermaid
sequenceDiagram
    participant Client as å®¢æˆ·ç«¯
    participant API as server/api.py
    participant Redis as Redis
    participant Worker as main_worker.py
    participant Task as server/tasks.py
    participant Pipeline as Pipeline (Pano/Ceph)
    participant ReportUtils as report_utils
    participant Callback as CallbackManager

    Client->>API: POST /api/v1/analyze
    API->>Redis: save_task(metadata_v2)
    API->>Task: analyze_task.delay(taskId)
    API-->>Client: 202 Accepted

    Worker->>Redis: BRPOP queue
    Redis-->>Worker: taskId
    Worker->>Task: analyze_task(taskId)
    Task->>Redis: get_task(taskId)
    Redis-->>Task: metadata_v2
    
    Task->>Task: æå– taskType, imagePath, patientInfo
    
    alt taskType == "panoramic"
        Task->>Pipeline: pipeline = PanoPipeline()
        Task->>Pipeline: run(image_path)
        
        Pipeline->>Pipeline: _load_image() [éªŒè¯æ–‡ä»¶]
        Pipeline->>Pipeline: _run_teeth_seg() [TODO]
        Pipeline->>Pipeline: _run_bone_density() [TODO]
        Pipeline->>Pipeline: _collect_results()
        
        Pipeline->>ReportUtils: generate_standard_output(results)
        ReportUtils-->>Pipeline: data_dict (ç©ºç»“æ„)
        
        Pipeline-->>Task: return data_dict
        
    else taskType == "cephalometric"
        Task->>Pipeline: pipeline = CephPipeline()
        Task->>Pipeline: run(image_path, patient_info)
        
        Pipeline->>Pipeline: _validate_patient_info()
        Pipeline->>Pipeline: _load_image() [éªŒè¯æ–‡ä»¶]
        Pipeline->>Pipeline: _run_landmark_detection() [TODO]
        Pipeline->>Pipeline: _run_measurements() [TODO]
        Pipeline->>Pipeline: _collect_results()
        
        Pipeline->>ReportUtils: generate_standard_output(results, patient_info)
        ReportUtils-->>Pipeline: data_dict (ç©ºç»“æ„)
        
        Pipeline-->>Task: return data_dict
    end
    
    Task->>Task: æ„é€  CallbackPayload v3
    Task->>Callback: send_callback(url, payload_v3)
    Callback->>Client: POST callbackUrl
    Client-->>Callback: 200 OK
    
    Task->>Redis: delete_task(taskId)
```

---

## å…­ã€éªŒè¯ä¸æµ‹è¯•

### æ­¥éª¤ 1 éªŒè¯ï¼šBasePipeline

```bash
# æµ‹è¯•å¯¼å…¥
python -c "from pipelines.base_pipeline import BasePipeline; print('OK')"

# æµ‹è¯•æŠ½è±¡ç±»
python -c "
from pipelines.base_pipeline import BasePipeline

# å°è¯•å®ä¾‹åŒ–æŠ½è±¡ç±»ï¼ˆåº”è¯¥å¤±è´¥ï¼‰
try:
    pipeline = BasePipeline()
    print('FAIL: Should not be able to instantiate abstract class')
except TypeError as e:
    print('OK: Cannot instantiate abstract class')
"
```

### æ­¥éª¤ 2 éªŒè¯ï¼šPanoPipeline

```bash
# æµ‹è¯• PanoPipeline å®ä¾‹åŒ–å’Œè¿è¡Œ
python -c "
import os
from pipelines.pano.pano_pipeline import PanoPipeline

# åˆ›å»ºæµ‹è¯•å›¾åƒ
os.makedirs('tmp', exist_ok=True)
test_image = 'tmp/test_pano.jpg'
with open(test_image, 'w') as f:
    f.write('dummy')

# æµ‹è¯• Pipeline
pipeline = PanoPipeline()
result = pipeline.run(test_image)

# éªŒè¯ç»“æœ
assert isinstance(result, dict), 'Result should be dict'
assert 'Metadata' in result, 'Should have Metadata'
assert 'AnatomyResults' in result, 'Should have AnatomyResults'
print('OK: PanoPipeline test passed')
"
```

### æ­¥éª¤ 3 éªŒè¯ï¼šCephPipeline

```bash
# æµ‹è¯• CephPipeline å®ä¾‹åŒ–å’Œè¿è¡Œ
python -c "
import os
from pipelines.ceph.ceph_pipeline import CephPipeline

# åˆ›å»ºæµ‹è¯•å›¾åƒ
os.makedirs('tmp', exist_ok=True)
test_image = 'tmp/test_ceph.jpg'
with open(test_image, 'w') as f:
    f.write('dummy')

# æµ‹è¯• Pipelineï¼ˆæœ‰æ•ˆ patient_infoï¼‰
patient_info = {'gender': 'Male', 'DentalAgeStage': 'Permanent'}
pipeline = CephPipeline()
result = pipeline.run(test_image, patient_info)

# éªŒè¯ç»“æœ
assert isinstance(result, dict), 'Result should be dict'
assert 'ImageSpacing' in result, 'Should have ImageSpacing'
assert 'KeyPoints' in result, 'Should have KeyPoints'
print('OK: CephPipeline test passed')

# æµ‹è¯•æ— æ•ˆ patient_infoï¼ˆåº”è¯¥å¤±è´¥ï¼‰
try:
    pipeline.run(test_image, {'gender': 'Invalid'})
    print('FAIL: Should reject invalid patient_info')
except ValueError as e:
    print('OK: Invalid patient_info rejected')
"
```

### æ­¥éª¤ 4 éªŒè¯ï¼šç«¯åˆ°ç«¯æµ‹è¯•

```bash
# 1. å¯åŠ¨ Redisï¼ˆç¡®ä¿è¿è¡Œä¸­ï¼‰

# 2. å¯åŠ¨ Workerï¼ˆç»ˆç«¯ 1ï¼‰
cd D:\ç¡•å£«æ–‡æ¡£\é¡¹ç›®\å£è…”\code\Xray-inference
python main_worker.py

# 3. å¯åŠ¨ API æœåŠ¡ï¼ˆç»ˆç«¯ 2ï¼‰
python main_api.py

# 4. å‘é€æµ‹è¯•è¯·æ±‚ï¼ˆç»ˆç«¯ 3ï¼‰
python send_request_test.py
```

**æ£€æŸ¥ç‚¹**:
- âœ… API æœåŠ¡å¯åŠ¨æ— é”™è¯¯
- âœ… Worker å¯åŠ¨æ— é”™è¯¯
- âœ… è¯·æ±‚è¿”å› 202 Accepted
- âœ… Worker æ—¥å¿—æ˜¾ç¤º Pipeline æ‰§è¡Œ
- âœ… å›è°ƒæˆåŠŸï¼ˆæ£€æŸ¥å›è°ƒæœåŠ¡å™¨æ—¥å¿—ï¼‰
- âœ… å›è°ƒ payload åŒ…å«æ­£ç¡®çš„å­—æ®µç»“æ„

---

## ä¸ƒã€é£é™©ä¸æ³¨æ„äº‹é¡¹

### 1. æ–‡ä»¶è·¯å¾„é—®é¢˜

**é£é™©**: Windows è·¯å¾„åˆ†éš”ç¬¦å¯èƒ½å¯¼è‡´é—®é¢˜

**åº”å¯¹**:
- ç»Ÿä¸€ä½¿ç”¨ `os.path.join()` æˆ– `pathlib.Path`
- æµ‹è¯•æ—¶ä½¿ç”¨ç›¸å¯¹è·¯å¾„

### 2. å¯¼å…¥é”™è¯¯

**é£é™©**: Python æ¨¡å—å¯¼å…¥è·¯å¾„é—®é¢˜

**åº”å¯¹**:
- ç¡®ä¿ä»é¡¹ç›®æ ¹ç›®å½•è¿è¡Œ
- ä½¿ç”¨ç»å¯¹å¯¼å…¥ï¼ˆ`from pipelines.xxx import yyy`ï¼‰
- ç¡®ä¿ `__init__.py` æ–‡ä»¶å­˜åœ¨

### 3. æŠ½è±¡ç±»å®ä¾‹åŒ–

**é£é™©**: ç›´æ¥å®ä¾‹åŒ– BasePipeline ä¼šæŠ¥é”™

**åº”å¯¹**:
- åœ¨æµ‹è¯•ä¸­æ˜ç¡®æ•è· TypeError
- æ–‡æ¡£ä¸­è¯´æ˜ BasePipeline æ˜¯æŠ½è±¡ç±»

### 4. æ‚£è€…ä¿¡æ¯éªŒè¯

**é£é™©**: CephPipeline ç¼ºå°‘ patient_info ä¼šå¯¼è‡´é”™è¯¯

**åº”å¯¹**:
- åœ¨ `_validate_patient_info()` ä¸­æä¾›æ˜ç¡®çš„é”™è¯¯ä¿¡æ¯
- åœ¨ API å±‚åšåˆæ­¥éªŒè¯ï¼ˆv2 å·²å®ç°ï¼‰

### 5. ç©ºç»“æ„è¿”å›

**é£é™©**: v3 è¿”å›ç©ºç»“æ„å¯èƒ½è¯¯å¯¼ç”¨æˆ·

**åº”å¯¹**:
- åœ¨æ—¥å¿—ä¸­æ˜ç¡®æ ‡æ³¨ "TODO" å’Œ "not fully implemented"
- æ–‡æ¡£ä¸­è¯´æ˜ v3 ä»…ä¸ºæ¥å£è®¾è®¡ï¼Œv4 å®ç°çœŸå®é€»è¾‘

---

## å…«ã€v3 â†’ v4 æ¼”è¿›è·¯å¾„

### v3 å®Œæˆåçš„çŠ¶æ€

- âœ… æ¶æ„æ¸…æ™°ï¼šBasePipeline â†’ PanoPipeline/CephPipeline
- âœ… æ¥å£ç¨³å®šï¼š`run()` æ–¹æ³•ç­¾åç¡®å®š
- âœ… èŒè´£åˆ†ç¦»ï¼šPipelineï¼ˆæ¨ç†ï¼‰ + report_utilsï¼ˆæ ¼å¼åŒ–ï¼‰
- âœ… å¯è¿è¡Œå¯éªŒè¯ï¼šç«¯åˆ°ç«¯æµç¨‹æ‰“é€šï¼ˆè™½ç„¶è¿”å›ç©ºç»“æ„ï¼‰

### v4 éœ€è¦å®ç°çš„å†…å®¹

1. **å¡«å…… BasePipeline çš„å…±äº«æ–¹æ³•**
   - `_load_image()`: çœŸå®çš„å›¾åƒåŠ è½½ï¼ˆJPG/PNGï¼ŒDICOM å»¶åï¼‰
   - `_validate_image()`: çœŸå®çš„å›¾åƒéªŒè¯ï¼ˆå°ºå¯¸ã€æ ¼å¼ç­‰ï¼‰

2. **å¡«å…… PanoPipeline çš„å­æ¨¡å—è°ƒç”¨**
   - `_run_teeth_seg()`: åŠ è½½æ¨¡å‹ã€æ¨ç†ã€åå¤„ç†
   - `_run_bone_density()`: å®ç°éª¨å¯†åº¦åˆ†æ
   - `_run_joint_detection()`: å®ç°å…³èŠ‚æ£€æµ‹

3. **å¡«å…… CephPipeline çš„å­æ¨¡å—è°ƒç”¨**
   - `_run_landmark_detection()`: åŠ è½½æ¨¡å‹ã€æ¨ç†å…³é”®ç‚¹
   - `_run_measurements()`: åŸºäºå…³é”®ç‚¹è®¡ç®—æµ‹é‡å€¼

4. **å®ç° report_utils çš„æ ¼å¼åŒ–é€»è¾‘**
   - `pano_report_utils.generate_standard_output()`: å°†æ¨ç†ç»“æœæ˜ å°„åˆ°è§„èŒƒ JSON
   - `ceph_report_utils.generate_standard_output()`: å°†æ¨ç†ç»“æœæ˜ å°„åˆ°è§„èŒƒ JSON

5. **æ·»åŠ é”™è¯¯å¤„ç†**
   - åœ¨ tasks.py ä¸­å®ç° FAILURE å›è°ƒ
   - åœ¨ Pipeline ä¸­æ·»åŠ å¼‚å¸¸å¤„ç†

### v4 çš„å¥½å¤„

- âœ… æ— éœ€ä¿®æ”¹ tasks.pyï¼ˆæ¥å£å·²ç¨³å®šï¼‰
- âœ… æ— éœ€ä¿®æ”¹ API å±‚ï¼ˆå›è°ƒæ ¼å¼å·²ç¡®å®šï¼‰
- âœ… å¯ä»¥é€ä¸ªå­æ¨¡å—å®ç°å’Œæµ‹è¯•
- âœ… æ˜“äºå¹¶è¡Œå¼€å‘ï¼ˆä¸åŒå­æ¨¡å—ï¼‰

---

## ä¹ã€æ€»ç»“

### v3 æ¶æ„ä¼˜åŠ¿

1. **èŒè´£æ¸…æ™°**
   - `server/tasks.py` â†’ è°ƒåº¦å±‚ï¼ˆé€‰æ‹© Pipelineã€ä¼ é€’å‚æ•°ï¼‰
   - `pipelines/*_pipeline` â†’ æ¨ç†å±‚ï¼ˆåè°ƒå­æ¨¡å—ï¼‰
   - `pipelines/*/utils/*` â†’ æ ¼å¼åŒ–å±‚ï¼ˆç”Ÿæˆè§„èŒƒ JSONï¼‰

2. **æ˜“äºæµ‹è¯•**
   - å¯ä»¥ç‹¬ç«‹æµ‹è¯• Pipelineï¼ˆä¸ä¾èµ– Celeryï¼‰
   - å¯ä»¥ç‹¬ç«‹æµ‹è¯• report_utilsï¼ˆä¸ä¾èµ–æ¨ç†ï¼‰

3. **æ˜“äºæ¼”è¿›**
   - v3 â†’ v4ï¼šå¡«å…… TODOï¼Œæ— éœ€ä¿®æ”¹æ¥å£
   - v4 â†’ v5ï¼šæ·»åŠ æ–°å­æ¨¡å—ï¼Œåªä¿®æ”¹ Pipeline
   - v5 â†’ v6ï¼šæ”¯æŒ DICOMï¼Œåªä¿®æ”¹ `base_pipeline._load_image()`

4. **ç¬¦åˆ SOLID åŸåˆ™**
   - **å•ä¸€èŒè´£**ï¼šæ¯ä¸ªç±»åªè´Ÿè´£ä¸€ä»¶äº‹
   - **å¼€é—­åŸåˆ™**ï¼šå¯¹æ‰©å±•å¼€æ”¾ï¼Œå¯¹ä¿®æ”¹å°é—­
   - **ä¾èµ–å€’ç½®**ï¼štasks.py ä¾èµ–æŠ½è±¡æ¥å£ï¼Œä¸ä¾èµ–å…·ä½“å®ç°

### å¼€å‘é¡ºåºé‡è¦æ€§

**ä¸ºä»€ä¹ˆå¿…é¡»æŒ‰ç…§ æ­¥éª¤1 â†’ æ­¥éª¤2 â†’ æ­¥éª¤3 â†’ æ­¥éª¤4 çš„é¡ºåºï¼Ÿ**

- **æ­¥éª¤1ï¼ˆBasePipelineï¼‰** æ˜¯åŸºç¡€ï¼Œæ­¥éª¤2å’Œ3ä¾èµ–å®ƒ
- **æ­¥éª¤2ï¼ˆPanoPipelineï¼‰** å’Œ **æ­¥éª¤3ï¼ˆCephPipelineï¼‰** å¯ä»¥å¹¶è¡Œï¼Œä½†éƒ½éœ€è¦æ­¥éª¤1å®Œæˆ
- **æ­¥éª¤4ï¼ˆtasks.pyï¼‰** éœ€è¦æ­¥éª¤2å’Œ3å®Œæˆåæ‰èƒ½è°ƒç”¨

### éªŒè¯çš„é‡è¦æ€§

æ¯ä¸ªæ­¥éª¤å®Œæˆåéƒ½å¿…é¡»éªŒè¯ï¼š
- âœ… å¯¼å…¥æ— é”™è¯¯
- âœ… å•å…ƒæµ‹è¯•é€šè¿‡
- âœ… ç¨‹åºå¯æ­£å¸¸å¯åŠ¨
- âœ… ä¸å½±å“ç°æœ‰åŠŸèƒ½

---

## é™„å½•

### A. å®Œæ•´æ–‡ä»¶åˆ—è¡¨

**v3 éœ€è¦ä¿®æ”¹/æ–°å¢çš„æ–‡ä»¶**:

```
v3 å˜æ›´æ–‡ä»¶:
â”œâ”€â”€ pipelines/
â”‚   â”œâ”€â”€ base_pipeline.py              âœ… æ–°å¢ï¼ˆçº¦ 150 è¡Œï¼‰
â”‚   â”œâ”€â”€ pano/
â”‚   â”‚   â”œâ”€â”€ pano_pipeline.py          âœ… é‡æ„ï¼ˆçº¦ 200 è¡Œï¼‰
â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”‚       â””â”€â”€ pano_report_utils.py  âœ… æ¥å£æ˜ç¡®ï¼ˆçº¦ 60 è¡Œï¼‰
â”‚   â””â”€â”€ ceph/
â”‚       â”œâ”€â”€ ceph_pipeline.py          âœ… é‡æ„ï¼ˆçº¦ 250 è¡Œï¼‰
â”‚       â””â”€â”€ utils/
â”‚           â””â”€â”€ ceph_report_utils.py  âœ… æ¥å£æ˜ç¡®ï¼ˆçº¦ 60 è¡Œï¼‰
â””â”€â”€ server/
    â””â”€â”€ tasks.py                      âœ… ä¿®æ”¹ï¼ˆçº¦ 220 è¡Œï¼Œç§»é™¤ load_mock_dataï¼‰
```

### B. å…³é”®æ¥å£ç­¾å

```python
# BasePipeline
class BasePipeline(ABC):
    def run(self, image_path: str, **kwargs) -> dict: ...

# PanoPipeline
class PanoPipeline(BasePipeline):
    def run(self, image_path: str) -> dict: ...

# CephPipeline
class CephPipeline(BasePipeline):
    def run(self, image_path: str, patient_info: dict) -> dict: ...

# pano_report_utils
def generate_standard_output(inference_results: dict) -> dict: ...

# ceph_report_utils
def generate_standard_output(inference_results: dict, patient_info: dict) -> dict: ...
```

### C. æ—¥å¿—è¾“å‡ºç¤ºä¾‹

```
[INFO] PanoPipeline initialized
[INFO] [panoramic] å¼€å§‹å…¨æ™¯ç‰‡æ¨ç†: image_path=tmp/test.jpg
[INFO] Image file validated: tmp/test.jpg
[INFO] [panoramic] ç‰™é½¿åˆ†å‰²: TODO
[INFO] [panoramic] éª¨å¯†åº¦åˆ†æ: TODO
[INFO] [panoramic] å…³èŠ‚æ£€æµ‹: TODO
[INFO] [panoramic] æ”¶é›†ç»“æœ: 3 modules
[INFO] Generating standard output for panoramic analysis
[WARNING] generate_standard_output not fully implemented (TODO)
[INFO] [panoramic] å…¨æ™¯ç‰‡æ¨ç†å®Œæˆ: data keys: ['Metadata', 'AnatomyResults', ...]
```

---

**æ–‡æ¡£ç‰ˆæœ¬**: v3.0  
**æœ€åæ›´æ–°**: 2024-11-17  
**ç¼–ç åŸåˆ™**: æ¸è¿›å¼å°æ­¥è¿­ä»£ï¼Œæ¯æ­¥ç‹¬ç«‹å®Œæˆã€å¯éªŒè¯ã€å¯è¿è¡Œ  
**ä¸‹ä¸€æ­¥**: æ‰§è¡Œæ­¥éª¤1ï¼Œåˆ›å»º BasePipeline åŸºç±»

---

**å‡†å¤‡å¼€å§‹ç¼–ç ï¼** ğŸš€

