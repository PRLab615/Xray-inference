

1. 核心架构原则

本架构的核心原则是职责分离 (Separation of Concerns)。根据规范要求，AI 服务必须能够处理耗时（可达数分钟）的计算任务，同时必须在入口处立即（1 秒内）返回 HTTP 202 Accepted 响应。
为保证推理引擎的可拓展性与健壮性，本方案采用多进程异步架构，将“网络接口 服务”与“AI 计算”彻底解耦。
1.1 异步双进程模型

我们将同一个服务应用拆分为两个独立的进程角色，各司其职：
- API 服务进程 (P1):
  - 职责： 充当轻量级的前端。它唯一的职责是对接业务后端（甲方）传递处理 HTTP 请求、验证参数（实现 4xx 错误码）、将任务推入队列，并立即返回 202 响应。
  - 特性： 高并发、低延迟。此进程绝不执行任何耗时的 AI 计算。
- Worker 服务进程 (P2):
  - 职责： 充当重量级的计算后端。它唯一的职责是监听任务队列，获取任务，并调用 pipelines 模块执行密集的 AI 分析。
  - 特性： 高吞吐、计算密集。此进程绝不处理任何传入的 HTTP 请求。

1.2 核心枢纽：Redis

P1 和 P2 两个独立进程需要一个共享的“中介”来进行通信和状态同步。本方案采用 Redis 担任此枢纽角色，它同时实现两个关键功能：
1. 消息队列 (Message Broker):
  - P1 (API) 作为生产者，在验证请求后，将 taskId 放入 Redis 队列。
  - P2 (Worker) 作为消费者，从 Redis 队列中拉取 taskId。
  - 这实现了 P1 与 P2 之间的异步解耦和流量削峰。
2. 状态存储 (State Store):
  - P1 在接收请求时，必须将 (taskId, callbackUrl, metadata) 键值对存入 Redis。
  - P2 在数分钟后完成计算时，通过 taskId 从 Redis 取回对应的 callbackUrl，以执行正确的回调。
  - 这解决了异步架构中“跨时间、跨进程”的状态记忆问题。

---

2. 完整数据流

以下是单个 taskId 从请求到回调的完整生命周期：
1. [客户端] 发送 POST /api/v1/analyze 请求。
2. [API 服务 (P1)] (server/api.py) 接收请求。
3. server/schemas.py 验证请求体。若失败，P1 立即返回 错误码 。
4. P1 验证通过，生成 taskId。
5. P1 调用 server/core/persistence.py，将 (taskId, callbackUrl, ...) 写入 Redis。
6. P1 调用 server/tasks.py，将 taskId 推入 Redis 队列。
7. P1 立即向 [客户端] 返回 HTTP 202 Accepted。
8. (此时 P1 的 HTTP 事务已结束)
9. [Worker 服务 (P2)] (server/tasks.py) 监听到 Redis 队列中的新 taskId。
10. P2 从队列中获取 taskId，并从 Redis 状态存储中取回任务详情。
11. P2 根据 taskType 实例化 pipelines.pano.PanoPipeline。
12. P2 调用 pipeline.run() 执行AI计算。若AI模型执行失败，tasks.py 捕获异常并生成 12xxx 错误码。
13. P2 获得 data (成功JSON) 或 error (失败JSON)。
14. P2 调用 server/core/callback.py 触发回调。
15. callback.py 从 Redis 状态存储中取回 taskId 对应的 callbackUrl。
16. callback.py 向该 callbackUrl 发送 POST 回调请求（内置规范 1.4.3 的重试和超时逻辑）。
17. [客户端] 收到回调，返回 200 OK。
18. 任务流程结束。

---

3. 统一服务目录结构

此结构将服务层 (server/) 与算法核心 (pipelines/) 整合在同一仓库中。
inference-service/
│
├── .gitignore
├── requirements.txt       # Python 依赖 (fastapi, uvicorn, celery, redis, numpy...)
├── config.yaml            # 全局配置 (Redis URL, 队列名, 模型路径)
├── Dockerfile             # 【部署】服务容器化打包配置
├── docker-compose.yml     # 【部署】服务编排“一键启动”配置
│
├── main_api.py            # P1: API 服务启动入口 (Uvicorn)
├── main_worker.py         # P2: Worker 服务启动入口 (Celery)
│
├── main_cli.py            # CLI 批量推理入口
├── webui.py               # 测试 Web 前端入口
│
├── server/                # 【服务层】负责 API, 队列, 回调
│   │
│   ├── __init__.py
│   ├── api.py             # 核心: 定义 API 路由 (202/400 逻辑)
│   ├── schemas.py         # 核心: 定义 Pydantic 请求体验证 (10001 错误)
│   ├── worker.py          # 异步: 定义 Celery/RQ 应用实例
│   ├── tasks.py           # 异步: 定义 AI 任务, 按 taskType 调用 pipelines
│   │
│   └── core/              # 服务核心组件
│       ├── __init__.py
│       ├── persistence.py # 核心: 任务状态持久化 (Redis 读/写)
│       └── callback.py    # 核心: 回调管理器 (实现 POST 回调, 1.4.3 重试)
│
│
├── pipelines/             
│   │
│   ├── pano/              # 全景片推理系统
│   │   ├── __init__.py
│   │   ├── pano_pipeline.py # (由 server/tasks.py 调用)
│   │   ├── modules/
│   │   │   ├── teeth_seg/
│   │   │   │   ├── predictor.py
│   │   │   │   ├── pre_post.py
│   │   │   │   └── config.yaml
│   │   │   ├── bone_density/
│   │   │   └── ...
│   │   ├── utils/
│   │   │   ├── pano_post_rules.py # (负责生成规范 JSON)
│   │   │   └── ...
│   │   └── evaluation/
│   │       ├── eval_pano.py
│   │       └── metrics.py
│   │
│   ├── ceph/              # 侧位片推理系统
│   │   ├── __init__.py
│   │   ├── ceph_pipeline.py # (由 server/tasks.py 调用)
│   │   ├── modules/
│   │   │   └── ...
│   │   ├── utils/
│   │   │   ├── ceph_report_utils.py # (负责生成规范 JSON)
│   │   │   └── ...
│   │   └── evaluation/
│   │       ├── eval_ceph.py
│   │       └── metrics.py
│   │
│   └── base_pipeline.py     # 共享的 Pipeline 基础类
│
│
└── tools/                 # 通用分析、调试工具
    ├── compare_results.py
    └── visualize_masks.py

